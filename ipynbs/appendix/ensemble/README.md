# 集成方法

集成方法是通过构建并结合多个个体学习器来完成学习任务,获得比单个个体学习器更好的泛化能力.集成方法的核心思想可以用一句话说明:`三个臭皮匠顶个诸葛亮`.比如在二分类问题中,多个独立的简单分类器采用简单投票的结合策略时,根据[Hoeffding不等式](https://en.wikipedia.org/wiki/Hoeffding%27s_inequality)集成的分类器的错误概率随着简单分类器的个数增加而指数下降.参看西瓜书第八章.

集成方法通常分为两种:

+ 并行方法,个体学习器的构建过程相互独立,然后对它们的预测结果进行结合.结合的方式包括
    - 平均法,包括简单平均,加权平均
    - 投票法,包括绝对多数投票,相对多数投票,加权投票

例如:Bagging方法, 随机森林等

+ boosting方法,个体学习器是通过对之前学习器的表现对训练样本分布调整依次构建的,并且每一个基估计器都尝试去减少组合估计器的偏差.通俗地讲,就是后来的个体学习器在之前学习器预测错的样本上重点学习来弥补之前学习器的错误.

例如: AdaBoost,梯度提升树等