{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# sklearn处理超大规模数据\n",
    "\n",
    "处理超大规模数据(单机内存/硬盘无法容纳)是现如今可能碰到的问题之一,这当然不光是sklearn碰到的难题.sklearn的解决方法是(部分)模型使用`partial_fit`接口实现增量学习.\n",
    "\n",
    "支持增量学习的模型有:\n",
    "\n",
    "+ Classification(分类)\n",
    "    + sklearn.naive_bayes.MultinomialNB\n",
    "    + sklearn.naive_bayes.BernoulliNB\n",
    "    + sklearn.linear_model.Perceptron\n",
    "    + sklearn.linear_model.SGDClassifier\n",
    "    + sklearn.linear_model.PassiveAggressiveClassifier\n",
    "    + sklearn.neural_network.MLPClassifier\n",
    "+ Regression(回归)\n",
    "    + sklearn.linear_model.SGDRegressor\n",
    "    + sklearn.linear_model.PassiveAggressiveRegressor\n",
    "    + sklearn.neural_network.MLPRegressor\n",
    "+ Clustering(聚类)\n",
    "    + sklearn.cluster.MiniBatchKMeans\n",
    "    + sklearn.cluster.Birch\n",
    "+ Decomposition/feature Extraction(分解/特征提取)\n",
    "    + sklearn.decomposition.MiniBatchDictionaryLearning\n",
    "    + sklearn.decomposition.IncrementalPCA\n",
    "    + sklearn.decomposition.LatentDirichletAllocation\n",
    "+ Preprocessing（预处理）\n",
    "    + sklearn.preprocessing.StandardScaler\n",
    "    + sklearn.preprocessing.MinMaxScaler\n",
    "    + sklearn.preprocessing.MaxAbsScaler\n",
    "    \n",
    "可以看到能够处理大规模数据的主要是一些简单的线性模型."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
