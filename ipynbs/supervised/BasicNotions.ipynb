{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "在这里给大家罗列一下监督学习中常见的概念.\n",
    "\n",
    "* 带标签的d维数据:数据有d个预测变量和标签,$\\{ \\vec{x}, y:\\vec{x} \\in R^d, y\\in Y \\}$,其中$Y$为标签集\n",
    "* 二元和多元:如果标签集有两个元素,叫做二元;如果含有更多元素,叫做多元\n",
    "* 分类器:有监督学习的分类问题中,面对带标签的数据,我们学习到的用来预测标签的模型叫做分类器\n",
    "* 超平面:d维线性空间$S = \\{ \\vec{x} =(x_1,x_2,x_3,...,x_d), x_i \\in {-\\infty,\\infty} \\forall i \\in [1,d]\\}$中的$d-1$维子空间,比如$x_1*w_1 + x_2*w_2 + ... + x_d*w_d =0$这个线性方程确定的平面就是d维空间中的一个超平面\n",
    "* 线性可分:d维线性空间中,一组二元的d维数据集,如果可以根据标签被一个超平面完美得分割,我们就说这个数据集线性可分\n",
    "* 分隔超平面:一组带标签的d维数据线性可分,那个超平面就叫做分隔超平面\n",
    "* 线性分类器:分类问题中通过预测变量的线性组合来做出分类决策的模型\n",
    "* 学习理论:人工智能的一个分支,用来研究机器学习算法的设计和分析\n",
    "* 错误边界:在学习理论中,错误边界是一个机器学习算法收敛需要的更新数或者收敛前犯错数的上界\n",
    "* (点到超平面的)函数距离和几何距离:在一个d维空间S中,一个超平面H由$x_1*w_1 + x_2*w_2 + ... + x_d*w_d =0$决定,点$\\vec{x} =(a_1,a_2,a_3,...,a_d)$到H的函数距离为$||a_1*w_1 + a_2*w_2 + ... + a_d*w_d||$,几何距离为$\\frac {||a_1*w_1 + a_2*w_2 + ... + a_d*w_d||} {||(w_1,x_2,...,x_d)||}$\n",
    "* 前馈神经网络和循环神经网络:如![图1](https://github.com/HAOzj/Classic-ML-Methods-Algo/blob/master/ipynbs/source/img/FeedForwardNeuralNetwork.png),神经网络中神经元如果没有形成环,这个神经网络就属于前馈神经网络,反之则属于循环神经网络\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
