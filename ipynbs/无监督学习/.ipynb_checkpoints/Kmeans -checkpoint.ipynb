{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means\n",
    "\n",
    "我们的第一讲贡献给K-means方法,这是一种聚类方法,用于讲数据点进行划分.我们常会把它和Lloyd算法,也就是K-means方法的一种实现算法混淆.\n",
    "\n",
    "K-means方法是1957年由Hugo Steinhaus提出,而\"K-means\"这个术语是James MacQueen在1967年第一次使用.它的思想是将数据点分到K个聚类(Clusters),使得每个点和所在聚类的中心的距离的平方和最小,也就是最小化intra-class variance,这里我们把这个intra-class variance叫做成本函数(cost function)。数学上就是\n",
    "$$ \\underset{S}{\\arg\\min} \\sum\\limits_{k}\\sum\\limits_{x_i \\in S(k)}  |x_i - \\mu_k| ^2 $$\n",
    "\n",
    "\n",
    "其中 $ \\mu_k $是各个聚类的中心，$ S(k) $是每个聚类的点的集合。\n",
    "\n",
    "## K-means的步骤\n",
    "\n",
    "我们以最常用的一种启发式算法(Heuristics)--Lloyd算法为例，介绍K-means方法\n",
    "\n",
    "K-means的一般步骤:\n",
    "\n",
    "1. 初始化K个聚类的中心,一般是在n个数据点中随机选择,n为数据集的基数\n",
    "2. 根据每个数据点到每个聚类中心的距离,将它分配到最近的聚类,然后更新聚类的中心,迭代直到收敛,也就是每个点的聚类不再改变.\n",
    "\n",
    "因为聚类一共有 $ n^K $ 种情况，每次迭代都会降低成本函数(聚类内所有点到x点的距离平方和是个二次函数,这个函数在x为聚点中心是取到最小值),所以我们总可以在有限时间内收敛.但是现实操作中,我们往往将迭代次数或者成本函数的改善用于终止函数.简单来讲,就是迭代i次终止,或者当某次迭代的结果对上次迭代的结果改善度小于某个阈值时终止.所以Lloyd的复杂度在固定迭代次数的情况下复杂度为$ O(n*K*d*i) $,其中d为数据点的维度.\n",
    "\n",
    "\n",
    "K-means方法一定会收敛,但不一定收敛到全局最优点(Lloyd算法就是一种启发式算法).初始化的K个聚点中心起着决定性作用,所以人们试着改进在选取初始聚点中心的方法.比如*K-means++*算法,就是想让初始K个聚类中心相互尽量离得远.\n",
    "\n",
    "它的具体步骤是:\n",
    "\n",
    "1. 随机选择第一个聚点中心\n",
    "2. 对数据集中剩下的每个点x,计算它和最近的聚点中心的距离$ d(x)$，将所有的$ d^2(x) $归一化求得概率$ g(x) $，这时所以剩下的点就对应$ (0,1) $上不重复的线段\n",
    "3. 随机得在$ (0,1) $上取值,该值落在的x点就成为新的聚点中心\n",
    "4. 重复步骤2和3,直到找到K个聚点中心\n",
    "5. K-means一般步骤2\n",
    "\n",
    "K-means方法中聚类的数量K,作为超参数([hyper parameters](https://baike.baidu.com/item/%E8%B6%85%E5%8F%82%E6%95%B0/3101858?fr=aladdin)),可以是提前给定的,也可以是以输入形式得到的.我们必须在训练前有一个K,一个坏的K会带来不好的结果,所以一般都会多训练几次来确定一个合适的K.\n",
    "\n",
    "K-means方法处理球面或者超球面的数据集时表现很好,也就是数据呈现比较明显的围绕几个中心分布的情况.但面对其他分布的数据集时表现一般,并且每次运行(run)时结果不一定相同.\n",
    "\n",
    "类似的方法有K-medoid和GMM(高斯混合模型).K-medoid和K-means的区别在于一般步骤2时,我们选择聚类的中心点,也就是离中心最近的那个数据点,而不是中心.这样做的好处是减少了极端值对聚类的影响,但加大了计算复杂度,因为每次更新都要计算聚类内每个点到聚类中心的距离,不适合于大规模的数据集.至于GMM,留待第三节讲.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing code/kmeans.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/kmeans.py\n",
    "import numpy as np\n",
    "from random import sample, randint\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "class DimensionError(ValueError):\n",
    "    pass\n",
    "\n",
    "\n",
    "def draw_2d(dataset,k,d,Center,Label):\n",
    "\n",
    "    colors = cm.rainbow(np.linspace(0, 1, k))\n",
    "    n = len(dataset)\n",
    "    if(d == 2):\n",
    "        Color = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'w']\n",
    "        Colors = [Color[i] for i in Label]\n",
    "        for i in range(n):\n",
    "            plt.scatter(dataset[i][0], dataset[i][1], color=Colors[i])\n",
    "        for i in range(k):\n",
    "            plt.scatter(Center[i][0], Center[i][1],\n",
    "                        color=Color[i], marker='D')\n",
    "        plt.show()\n",
    "    return(Center, Label)\n",
    "\n",
    "def init_centers(dataset,k,d):\n",
    "    print(\"init center\")\n",
    "    n = len(dataset)\n",
    "    for i in dataset:\n",
    "        if(len(i) != d):\n",
    "            raise DimensionError(\"Data points are not of the given dimension\")\n",
    "\n",
    "    # label stores the clustering of every point\n",
    "    label = [0 for j in range(n)]\n",
    "    # choose k distinct samples by random as initial centroids\n",
    "    center = sample(dataset, k)\n",
    "    print(\"initial centers are :\", center)\n",
    "    return center, label\n",
    "\n",
    "\n",
    "def _k_means(dataset, k, d,Center, Label,maxite=10,):\n",
    "    n = len(dataset)\n",
    "    change = 1\n",
    "    for ite in range(maxite):\n",
    "        if(change > 0):\n",
    "            print(ite, \"th iteration : \")\n",
    "            # sum is a list whose element are the sums of points in each cluster in form of array\n",
    "            Sum1 = [np.array([float(0) for x in range(d)]) for l in range(k)]\n",
    "            \n",
    "            # during every iteration, change and dist records the number of changed labels \n",
    "            #and the size of each clustering\n",
    "            change = 0\n",
    "            Dist = [0 for x in range(k)]\n",
    "            for j,value in enumerate(dataset):\n",
    "                # print \"let's look at \", j, \"th point\"\n",
    "                # kDist is a list storing the distancce between given point and K centers\n",
    "                KDist = [sum((np.array(value) - np.array(Center[i]))**2) for i in range(k)]\n",
    "                # dist is the distance between given point and ith center\n",
    "                clu = KDist.index(min(KDist))\n",
    "                # print clu\n",
    "                Dist[clu] += 1\n",
    "                Sum1[clu] += np.array(dataset[j])\n",
    "                if(Label[j] != clu):\n",
    "                    change += 1\n",
    "                    Label[j] = clu\n",
    "            # update of centers\n",
    "            for i in range(k):\n",
    "                Center[i] = Sum1[i] / float(Dist[i])\n",
    "            print(\"new centers are :\\n\", Center)\n",
    "            print(\"new label are : \", Label)\n",
    "\n",
    "    return Center, Label\n",
    "\n",
    "\n",
    "\n",
    "def k_means(dataset, k, d, maxite=10):\n",
    "    \"\"\"function to perform Lloyd algorithm. If data points are 2-dimentional,\n",
    "    it will plot all the points colorized according to their cluster\n",
    "    \n",
    "    Parameters:\n",
    "        dataset (Iterable): - a list of data points who are also a list of numbers\n",
    "        k (int): - number of clusters\n",
    "        d (int): - dimension of data points\n",
    "        maxite (int): - maximum of iterations\n",
    "\n",
    "    Returns:\n",
    "        List: - list of centers of k clusters, list of labels of n points\n",
    "\n",
    "    Raise:\n",
    "        DimensionError: - Data points are not of the given dimension\n",
    "    \"\"\"\n",
    "    Center, Label = init_centers(dataset, k, d)\n",
    "    Center, Label = _k_means(dataset, k, d,Center, Label)\n",
    "    draw_2d(dataset,k,d,Center,Label)\n",
    "    return Center, Label\n",
    "\n",
    "\n",
    "def main():\n",
    "    a = [2, 2]\n",
    "    b = [1, 2]\n",
    "    c = [1, 1]\n",
    "    d = [0, 0]\n",
    "    f = [3, 2]\n",
    "    dataset = [a, b, c, d, f]\n",
    "    dataset.append([1.5, 0])\n",
    "    dataset.append([3, 4])\n",
    "    res = Kmeans(dataset, 2, 2)\n",
    "    print(res)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
